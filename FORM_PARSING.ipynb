{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Form Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")\n",
    "from helper import get_openai_api_key, get_llama_cloud_api_key\n",
    "from IPython.display import display, HTML\n",
    "from helper import extract_html_content\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a2f78-d56f-4bbb-9664-3da5f90cf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142d4e-48b4-43ec-ac7c-b608a8ba23c7",
   "metadata": {},
   "source": [
    "## Parsing an Application Form with LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0039610-c02e-4e7e-9c9f-1dc56450543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=llama_cloud_api_key,\n",
    "    base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "    result_type=\"markdown\",\n",
    "    content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "    formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parser.load_data(\"data/fake_application_form.pdf\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53149fea-7383-4c39-a58c-5836857f69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_json = llm.complete(\n",
    "    f\"\"\"\n",
    "    This is a parsed form.\n",
    "    Convert it into a JSON object containing only the list \n",
    "    of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "    <form>{result.text}</form>. \n",
    "    Return JSON ONLY, no markdown.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_json.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "for field in fields:\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc1088-2bd3-4ce8-a491-e8acd9cbde6b",
   "metadata": {},
   "source": [
    "## Adding a Form Parser to the Workflow (first update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        \n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        \n",
    "        if os.path.exists(self.storage_dir):\n",
    "            \n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            \n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            \n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        \n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        \n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        \n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        for field in fields:\n",
    "            print(field)\n",
    "        return StopEvent(result=\"Dummy event\")\n",
    "\n",
    "    \n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> StopEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return StopEvent(result=response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = RAGWorkflow(timeout=60, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656e32f-19ce-4f45-883e-5c89cb800d9e",
   "metadata": {},
   "source": [
    "## Generating Questions (second update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479183ef-c912-4fb9-8b5d-348e1942e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str\n",
    "\n",
    "# new!\n",
    "class ResponseEvent(Event):\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16626b-75c7-4b2f-84c5-94688530cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        \n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        \n",
    "        if os.path.exists(self.storage_dir):\n",
    "            \n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            \n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            \n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        \n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        \n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        \n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        \n",
    "        for field in fields:\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=f\"How would you answer this question about the candidate? {field}\"\n",
    "            ))\n",
    "\n",
    "        \n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # new!\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> StopEvent:\n",
    "        \n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None \n",
    "\n",
    "        \n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "        return StopEvent(result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf0ba9-d3e7-4380-be07-368b6ec41f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = RAGWorkflow(timeout=120, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff7243",
   "metadata": {},
   "source": [
    "## Workflow Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6416a1f-c2c9-478b-b290-8cd89998da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW_FILE = \"workflows/form_parsing_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
